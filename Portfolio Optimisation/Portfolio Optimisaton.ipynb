{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15186dac-d729-4597-ab93-b6765ad3a813",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0ba59-7249-48a9-a7fc-f217c6b66907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2020-04-30 00:00:00\n",
      "End: 2021-04-30 00:00:00\n",
      "Future Start 2021-04-30 00:00:00\n",
      "Future End 2021-05-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import ssl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import riskfolio as rp\n",
    "\n",
    "import time\n",
    "\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Inputs \n",
    "\n",
    "bse_ticker = pd.read_csv('Master.csv')\n",
    "bse_ticker.set_index('NSE Ticker',inplace=True)\n",
    "cd = pd.read_csv('closing_dataset.csv',index_col='Date',parse_dates=True)\n",
    "\n",
    "para = {\n",
    "'OPM':[True,12,'>'],\n",
    "'CFO':[True,0,'>'],\n",
    "'Net Cash Flow':[True,0,'>']\n",
    "    }\n",
    "\n",
    "para_s = {\n",
    "    'Financing Margin %':[True,12,'>'],\n",
    "    'Net_Profit':[True,0,'>'],\n",
    "    'Net Cash Flow':[False,0,'>']\n",
    "}\n",
    "\n",
    "# Get the Closing Price Dataframe \n",
    "\n",
    "def closing_dataset_funtion(tickers,start,end):\n",
    "    df = yf.download(tickers, start=start, end=end,progress=False,show_errors=False)['Close']\n",
    "    return df\n",
    "# closing_dataset = closing_dataset_funtion(tickers,start,end)\n",
    "\n",
    "# close_index = list(bse_ticker.index)\n",
    "\n",
    "# closing_dataset = closing_dataset_funtion(close_index,'2017-01-01',end='2022-05-01')\n",
    "\n",
    "# closing_dataset.to_csv('closing_dataset.csv')\n",
    "\n",
    "# RSI Dataset Function\n",
    "\n",
    "def RSI_dataset_function(dataset,n2=14):\n",
    "    \n",
    "    close_price = dataset.copy()\n",
    "    \n",
    "    for i in close_price:\n",
    "        a = pd.DataFrame(close_price[i])\n",
    "        \n",
    "        # Omtting null values\n",
    "        a = a.dropna(axis=0)\n",
    "        \n",
    "        change = a.diff().dropna()\n",
    "        change\n",
    "        \n",
    "        change_up = change.clip(lower=0)\n",
    "        \n",
    "        change_down = (-1 * change.clip(upper=0)).abs()\n",
    "        \n",
    "\n",
    "        avg_up = change_up.rolling(n2).mean()\n",
    "    \n",
    "        avg_down = change_down.rolling(n2).mean().abs()\n",
    "\n",
    "        rs = avg_up/avg_down   # calculating rs\n",
    "        \n",
    "        rsi = 100-(100/(1+rs))  # calculating RSI\n",
    "        rsi.dropna(inplace=True)\n",
    "        close_price[i] = rsi\n",
    "    \n",
    "    return close_price\n",
    "# RSI_dataset = RSI_dataset_function(closing_dataset)\n",
    "\n",
    "# SMA Dataset Function\n",
    "\n",
    "def SMA_dataset_function(dataset,n=5):\n",
    "    close_price = dataset.copy()\n",
    "    return close_price.rolling(n).mean()\n",
    "# SMA_dataset = SMA_dataset_function(closing_dataset)\n",
    "\n",
    "# Get Slope\n",
    "\n",
    "### Function to get the Linear Regression Slopes\n",
    "def regr(x,y):\n",
    "    regr1 = LinearRegression()\n",
    "    regr1.fit(x,y)\n",
    "    return regr1.coef_\n",
    "\n",
    "## This function takes the input as the dataset. It returns the Slope of each and every column(stocks) of the dataset given\n",
    "#as input. And return it as a dataframe.\n",
    "\n",
    "def get_Slope(dataset): ## Input would be the Dataset\n",
    "    close_price = dataset.copy()\n",
    "    index_list = []\n",
    "    regr2 = []   ### Empty list to store the slope of the input dataset.\n",
    "    y_hat = close_price ### Defining y_hat which is same as dataset.\n",
    "    y_hat = y_hat.reset_index(drop=True)    ### Resetting the index so that date becomes a column.\n",
    "\n",
    "    for i in y_hat.columns[1:]:   #### Iterating through the columns of y_hat.\n",
    "        y = y_hat[i]   ### y is taken as the each data point of each and every column.\n",
    "        y.dropna(inplace=True)\n",
    "        if len(y)>0:\n",
    "            x = np.array(y.index).reshape(-1, 1)   ##The x axis taken as sequence of numbers. \n",
    "            regr2.append(regr(x,y))   ## Appending the coefficients to the empty list.\n",
    "            index_list.append(i)\n",
    "    return pd.DataFrame(regr2, index = index_list)   ### Return the Dataframe and the index is set as column names.\n",
    "# get_Slope(RSI_dataset[-40:-10]) ### Calling the function.\n",
    "\n",
    "### RSI Divergence Function\n",
    "\n",
    "def RSI_divergence_function(SMA_dataset,RSI_dataset):\n",
    "    SMA_slope = get_Slope(SMA_dataset)\n",
    "    SMA_slope.rename(columns={0:'SMA'},inplace=True)\n",
    "    RSI_slope = get_Slope(RSI_dataset)\n",
    "    RSI_slope.rename(columns={0:'RSI'},inplace=True)\n",
    "    divergence = pd.concat([SMA_slope,RSI_slope],axis=1)\n",
    "    divergence['divergence'] = True\n",
    "\n",
    "    for i in range(len(divergence)):\n",
    "        if not (divergence.iloc[i][0] < 0) & (divergence.iloc[i][1]>0):\n",
    "            divergence.divergence.iloc[i] = False\n",
    "    return divergence\n",
    "\n",
    "### RSI breakout function\n",
    "\n",
    "def RSI_breakout_function(new_RSI_dataset,breakout_RSI_dataset): \n",
    "    \"\"\"\n",
    "    input: two RSI dataset which is broken in two windows\n",
    "    \"\"\"\n",
    "     # taking the last value of both the windows\n",
    "    new_RSI_dataset = new_RSI_dataset[-1:]\n",
    "    breakout_RSI_dataset = breakout_RSI_dataset[-1:]\n",
    "    \n",
    "    # checking the last value of the last window is lesser than the latest window\n",
    "    RSI_breakout = pd.DataFrame(new_RSI_dataset.iloc[0] < breakout_RSI_dataset.iloc[0])\n",
    "    \n",
    "    # changing the name of the column\n",
    "    RSI_breakout.rename(columns={0:'RSI_breakout'},inplace=True)\n",
    "    \n",
    "    # returning RSI_breakout\n",
    "    return RSI_breakout\n",
    "\n",
    "### Breakout\n",
    "\n",
    "def breakout_function(dataset,breakout_window = 10,RSI_divergence_window = 30):\n",
    "    close_price = dataset.copy()\n",
    "#     print(dataset.shape)\n",
    "    \n",
    "    # tries to two dataset which is RSI and SMA\n",
    "    RSI_dataset = RSI_dataset_function(close_price)\n",
    "    SMA_dataset = SMA_dataset_function(close_price)\n",
    "#     print(RSI_dataset.shape)\n",
    "#     print(SMA_dataset.shape)\n",
    "    \n",
    "    \n",
    "    # Breaking the Dataset into Two Windows \n",
    "    \n",
    "    # RSI DIVERGENCE WINDOW\n",
    "    new_RSI_dataset = RSI_dataset[-RSI_divergence_window-breakout_window:-breakout_window]\n",
    "    new_SMA_dataset = SMA_dataset[-RSI_divergence_window-breakout_window:-breakout_window]\n",
    "#     print(new_RSI_dataset.shape)\n",
    "#     print(new_SMA_dataset.shape)\n",
    "\n",
    "    # BREAKOUT WINDOW\n",
    "    breakout_RSI_dataset = RSI_dataset[-breakout_window:]\n",
    "    breakout_SMA_dataset = SMA_dataset[-breakout_window:]\n",
    "#     print(breakout_RSI_dataset.shape)\n",
    "#     print(breakout_SMA_dataset.shape)\n",
    "    \n",
    "    # Calculating RSI Divergence\n",
    "    RSI_divergence = RSI_divergence_function(new_SMA_dataset,new_RSI_dataset)\n",
    "    \n",
    "    # Calculating Price Breakout\n",
    "#     price_breakout = price_breakout_function(new_SMA_dataset,breakout_SMA_dataset)\n",
    "\n",
    "    # Calculating RSI Breakout\n",
    "#     RSI_breakout = RSI_breakout_function(new_RSI_dataset,breakout_RSI_dataset)\n",
    "\n",
    "    \n",
    "    # Calculating Breakout SMA Slope\n",
    "    breakout_slope = get_Slope(breakout_SMA_dataset)\n",
    "    breakout_slope.rename(columns={0:'SMA_breakout'},inplace=True)\n",
    "    \n",
    "    # Calculating Breakout SMA Slope\n",
    "    breakout_RSI_slope = get_Slope(breakout_RSI_dataset)\n",
    "    breakout_RSI_slope.rename(columns={0:'RSI_breakout'},inplace=True)\n",
    "\n",
    "    \n",
    "    # Concatenating all the Dataframes\n",
    "    breakout = pd.concat([RSI_divergence,breakout_slope,breakout_RSI_slope],axis=1)\n",
    "    \n",
    "    # Adding a breakout column with \n",
    "    breakout['breakout'] = None\n",
    "    \n",
    "#     breakout\n",
    "    for i in range(len(breakout)):\n",
    "        if ((breakout.iloc[i][2] == True)and(breakout.iloc[i][3]>0)and breakout.iloc[i][4]>0):\n",
    "#         if ((breakout.iloc[i][2] == True)and(breakout.iloc[i][3]>0)):            \n",
    "#             print(i)\n",
    "#             print(True)\n",
    "            breakout.breakout[i] = True\n",
    "    return breakout\n",
    "\n",
    "# Screener.in Scrapping\n",
    "\n",
    "def fs_concat(pnl,bs,cf):\n",
    "    \"\"\"\n",
    "    This function takes in the pnl,bs,cf and concatenate them\n",
    "    \"\"\"\n",
    "    # concatenating the tables \n",
    "    fs = pd.concat([pnl,bs,cf])\n",
    "    \n",
    "    # setting the primary column as index \n",
    "    fs.set_index('Unnamed: 0',inplace=True)\n",
    "    fs = fs.T\n",
    "    return fs \n",
    "# fs_concat(pnl,bs,cf)\n",
    "\n",
    "def cagr_function(csg,cpg,spc,roe):\n",
    "    \"\"\"\n",
    "    This function takes in the csg, cpg, spc and roe table and concatenate them\n",
    "    \"\"\"\n",
    "    \n",
    "    # setting primary columns as index\n",
    "    csg.set_index('Compounded Sales Growth',inplace=True)\n",
    "    cpg.set_index(\"Compounded Profit Growth\",inplace=True)\n",
    "    spc.set_index(\"Stock Price CAGR\",inplace=True)\n",
    "    roe.set_index(\"Return on Equity\",inplace=True)\n",
    "\n",
    "    # concatenating\n",
    "    cagr = pd.concat([csg,cpg,spc,roe],axis=1)\n",
    "\n",
    "    return cagr\n",
    "# cagr_function(csg,cpg,spc,roe)\n",
    "\n",
    "def screener_scrape_function(ticker):\n",
    "    \"\"\"\n",
    "    This function takes in the BSE ticker for a company and returns a financial statements(pnl,bs,cf), CAGR and ratios for the respectice company\n",
    "    1. takes in the tickers\n",
    "    2. add the ticker to the screener.in url\n",
    "    3. extract the tables from above tickers\n",
    "    4. assign variable to the different tables\n",
    "    5. concatenate fs,pnl,cf table into single fs (financial statement) table\n",
    "    6. concatenate csg,cpg,spc,roe in cage table\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scrapping the tables from the url\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    \n",
    "    scraped = pd.read_html(f\"https://www.screener.in/company/{ticker}\")\n",
    "    \n",
    "    # assinging variables to different tables\n",
    "    qr = scraped[0] # Quaterly results\n",
    "    pnl = scraped[1] # profit and loss\n",
    "    csg = scraped[2] # compounded sales growth\n",
    "    cpg = scraped[3] # compunded profit growth \n",
    "    spc = scraped[4] # stock price CAGR\n",
    "    roe = scraped[5] # return on Equity\n",
    "    bs = scraped[6] # balance sheet \n",
    "    cf = scraped[7] # cash flow \n",
    "    ratios = scraped[8] # ratios \n",
    "#     shareholding = scraped[9] # shareholding pattern\n",
    "    \n",
    "    # concatenating pbl,bs,cf\n",
    "    fs = fs_concat(pnl,bs,cf)\n",
    "    \n",
    "    # concatenating csg,cpg,spc,roe\n",
    "    cagr = cagr_function(csg,cpg,spc,roe)\n",
    "    \n",
    "    # setting the first columns as index in ratios\n",
    "    ratios.set_index('Unnamed: 0',inplace=True)\n",
    "    \n",
    "    return fs,cagr,ratios.T\n",
    "# fs,cagr,ratios = screener_scrape_function(541988)\n",
    "\n",
    "def screener_data_function(lst,bse_list):\n",
    "    fs_final = pd.DataFrame()\n",
    "    cagr_final = pd.DataFrame()\n",
    "    ratios_final = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(bse_list)):\n",
    "#         print(bse_list[i])\n",
    "        if (bse_list[i] != 'BSE') &  (bse_list[i] != 'CDSL'):\n",
    "            time.sleep(2)\n",
    "            fs,cagr,ratios = screener_scrape_function(int(bse_list[i]))\n",
    "            fs = fs.reset_index()\n",
    "            fs['Company'] = lst[i]\n",
    "            fs_final = pd.concat([fs_final,fs])\n",
    "\n",
    "            cagr = cagr.reset_index()\n",
    "            cagr['Company'] = lst[i]\n",
    "            cagr_final = pd.concat([cagr_final,cagr])\n",
    "\n",
    "            ratios = ratios.reset_index()\n",
    "            ratios['Company'] = lst[i]\n",
    "            ratios_final = pd.concat([ratios_final,ratios])\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "            fs,cagr,ratios = screener_scrape_function(str(bse_list[i])+'/consolidated/')\n",
    "            fs = fs.reset_index()\n",
    "            fs['Company'] = lst[i]\n",
    "            fs_final = pd.concat([fs_final,fs])\n",
    "\n",
    "            cagr = cagr.reset_index()\n",
    "            cagr['Company'] = lst[i]\n",
    "            cagr_final = pd.concat([cagr_final,cagr])\n",
    "\n",
    "            ratios = ratios.reset_index()\n",
    "            ratios['Company'] = lst[i]\n",
    "            ratios_final = pd.concat([ratios_final,ratios])\n",
    "            \n",
    "        \n",
    "    return fs_final,cagr_final,ratios_final\n",
    "    \n",
    "\n",
    "def rename_columns(fs_final,cagr_final,ratios_final):\n",
    "    fs_rename ={\n",
    "        'index':'Year',\n",
    "        'OPM %':'OPM',\n",
    "        'Cash from Operating Activity\\xa0+':'CFO',\n",
    "        'Cash from Investing Activity\\xa0+':'CFI',\n",
    "        'Cash from Financing Activity\\xa0+':'CFF',\n",
    "        'Other Assets\\xa0+':'Other_Assets',\n",
    "        'Sales\\xa0+':'Sales',\n",
    "        'Expenses\\xa0+':'Expenses',\n",
    "        'Other Income\\xa0+':'Other_Income',\n",
    "        'Share Capital\\xa0+':'Share_Capital',\n",
    "        'Other Liabilities\\xa0+':'Other_Liabilities',\n",
    "        'Fixed Assets\\xa0+':'Fixed_Assets',\n",
    "        'Net Profit': 'Net_Profit'\n",
    "    }\n",
    "\n",
    "    fs_final.rename(columns=fs_rename,inplace=True)\n",
    "\n",
    "    cagr_rename = {\n",
    "        'index':'Year',\n",
    "        'Compounded Sales Growth.1':'Sales Growth',\n",
    "        'Compounded Profit Growth.1':'Profit Growth',\n",
    "        'Stock Price CAGR.1':'Stock Price Growth',\n",
    "        'Return on Equity.1':'Return on Equity.1'\n",
    "\n",
    "    }\n",
    "\n",
    "    cagr_final.rename(columns=cagr_rename, inplace=True)\n",
    "\n",
    "    ratios_rename = {\n",
    "        'index':'Year'\n",
    "    }\n",
    "\n",
    "    ratios_final.rename(columns=ratios_rename,inplace=True)\n",
    "# rename_columns()\n",
    "\n",
    "def remove_percentage_function(check_df):\n",
    "    percentage_list = ['Tax %','OPM','Dividend Payout %','Financing Margin %']\n",
    "    for column in percentage_list:\n",
    "        try:\n",
    "#             print(column)\n",
    "            for i in range(len(check_df[column])):\n",
    "\n",
    "\n",
    "                if type(check_df[column].iloc[i]) == str:\n",
    "                    if ',' in check_df[column].iloc[i]:\n",
    "                        check_df[column].iloc[i] = check_df[column].iloc[i].replace(',','')\n",
    "                    check_df[column].iloc[i] = check_df[column].iloc[i][:-1]\n",
    "                else:\n",
    "                    check_df[column].iloc[i] = 0 \n",
    "        except:\n",
    "            None\n",
    "# remove_percentage_function(check_df)\n",
    "\n",
    "def column_type_convertor(check_df):\n",
    "    for i in check_df:\n",
    "        if (i != 'Year') & (i!='Company') & (i!='Industry'):\n",
    "            check_df[i] = pd.to_numeric(check_df[i])\n",
    "# column_type_convertor(check_df)\n",
    "\n",
    "    # para = {\n",
    "    #     'OPM':[True,12,'>'],\n",
    "    #     'CFO':[True,0,'>'],\n",
    "    #     'Net Cash Flow':[True,0,'>']\n",
    "    # }\n",
    "    # para_s = {\n",
    "    #     'Financing Margin %':[True,12,'>'],\n",
    "    #     'Net_Profit':[True,0,'>'],\n",
    "    #     'Net Cash Flow':[False,0,'>']\n",
    "    # }\n",
    "    def filter_stocks(para,para_s,check_df):\n",
    "        df = check_df.copy()\n",
    "        df = df[df['Industry']!= 'Financial Services']\n",
    "\n",
    "        # Financial Service Comapny\n",
    "        df_s = check_df.copy()\n",
    "        df_s = df_s[df_s['Industry']== 'Financial Services']\n",
    "        df_s\n",
    "\n",
    "        filters = df.copy()\n",
    "        filters_s = df_s.copy()\n",
    "\n",
    "\n",
    "        for i in para:\n",
    "            if para[i][0]:\n",
    "                if para[i][2] == '>':\n",
    "                    filters = df[(df[i]>=para[i][1])]\n",
    "                elif para[i][2] == '<':\n",
    "                    filters = df[(df[i]<=para[i][1])]\n",
    "                else:\n",
    "                    filters = df[(df[i]==para[i][1])]\n",
    "            df = filters\n",
    "\n",
    "\n",
    "        if df_s.shape[0]>0:\n",
    "            try:\n",
    "                for i in para_s:\n",
    "                    if para_s[i][0]:\n",
    "                        if para_s[i][2] == '>':\n",
    "                            filters_s = df_s[(df_s[i]>=para_s[i][1])]\n",
    "                        elif para[i][2] == '<':\n",
    "                            filters_s = df_s[(df_s[i]<=para_s[i][1])]\n",
    "                        else:\n",
    "                            filters_s = df_s[(df_s[i]==para_s[i][1])]\n",
    "                    df_s = filters_s\n",
    "            except:\n",
    "                for i in para:\n",
    "                    if para[i][2] == '>':\n",
    "                        filters = df_s[(df_s[i]>=para[i][1])]\n",
    "                    elif para[i][2] == '<':\n",
    "                        filters = df_s[(df_s[i]<=para[i][1])]\n",
    "                    else:\n",
    "                        filters = df_s[(df_s[i]==para[i][1])]\n",
    "                    df_s = filters_s\n",
    "    #     print(df)\n",
    "    #     print(df_s.index)\n",
    "    #     display(check_df,df_s,df)\n",
    "        filtered_ticker = list(df['Company'].values) + list(df_s['Company'].values)\n",
    "        return filtered_ticker\n",
    "\n",
    "# year_1 = 'Dec 2019'\n",
    "# year_2 = 'Mar 2020'\n",
    "# check_df = fs_final[(fs_final['Year']==year_1) | (fs_final['Year']==year_2)]\n",
    "\n",
    "# filtered_ticker = list(check_df[(check_df['CFO']>0)]['Company'].values)\n",
    "\n",
    "# Get The Returns Dataframe \n",
    "\n",
    "def returns_dataset_funtion(filtered_ticker,closing_dataset):\n",
    "    return_df = pd.DataFrame() # Creating a empty Df\n",
    "    close_price = closing_dataset.copy() # Creating a copy of the closing dataset\n",
    "#     close_price.reset_index(inplace=True)\n",
    "\n",
    "    # for every company in filtered list. \n",
    "    for i in filtered_ticker:\n",
    "        a = close_price[i] # get a column from the closing price dataset\n",
    "        # Omtting null values\n",
    "        a = a.dropna(axis=0) # omit all the nan values\n",
    "        a = a.pct_change().dropna() # get a return and remove the first columns\n",
    "        return_df[i] = a\n",
    "\n",
    "    return return_df\n",
    "# returns_dataset = returns_dataset_funtion(filtered_ticker,closing_dataset)\n",
    "\n",
    "# HRP function\n",
    "\n",
    "def weightshrp(df1) :\n",
    "    port = rp.HCPortfolio(returns=df1)\n",
    "    model='HRP'\n",
    "    codependence = 'pearson'\n",
    "    rm = 'MV'\n",
    "    rf = 0\n",
    "    linkage = 'single'\n",
    "    max_k = 10\n",
    "    leaf_order = True\n",
    "    w = port.optimization(model=model,\n",
    "                          codependence=codependence,\n",
    "                          rm=rm,\n",
    "                          rf=rf,\n",
    "                          linkage=linkage,\n",
    "                          max_k=max_k,\n",
    "                          leaf_order=leaf_order)\n",
    "    return(w)\n",
    "# weightshrp(returns_dataset)\n",
    "\n",
    "# Part 1  \n",
    "\n",
    "# start = '2020-04-30'\n",
    "# end = '2021-04-30'\n",
    "# bse_ticker = pd.read_csv('Master.csv')\n",
    "# bse_ticker.set_index('NSE Ticker',inplace=True)\n",
    "# cd = pd.read_csv('closing_dataset.csv',index_col='Date',parse_dates=True)\n",
    "\n",
    "# breakout_window=10\n",
    "# RSI_divergence_window = 30\n",
    "\n",
    "\n",
    "def part_1(dataset,bse_ticker,start,end,breakout_window=10,RSI_divergence_window=40):\n",
    "    start_index = pd.date_range(start=start,end=end)\n",
    "#     future_index = pd.date_range(start=future_start,end=future_end)\n",
    " \n",
    "    # Part 1\n",
    "    closing_dataset = dataset.loc[dataset.index.intersection(start_index)]\n",
    "    \n",
    "    RSI_dataset = RSI_dataset_function(closing_dataset)\n",
    "    SMA_dataset = SMA_dataset_function(closing_dataset)\n",
    "#     print(\"Part 1 Done\")\n",
    "    \n",
    "    # Part 2 \n",
    "    a = breakout_function(closing_dataset,breakout_window=breakout_window,RSI_divergence_window=RSI_divergence_window)\n",
    "    \n",
    "    breakout = a.loc[a['breakout']==True]\n",
    "    z = list(breakout.index)\n",
    "    breakout['Industry'] = bse_ticker['Industry'].loc[z].values\n",
    "#     print(breakout.index)\n",
    "    display(breakout) ######\n",
    "    lst = list(breakout.index)\n",
    "#     print(lst)\n",
    "    b = list(bse_ticker.loc[lst]['BSE Ticker'].values)\n",
    "#     print(b)\n",
    "    return lst,b,closing_dataset\n",
    "    \n",
    "\n",
    "# lst,b,closing_dataset = part_1(cd,bse_ticker,start=start,end=end,breakout_window=breakout_window,RSI_divergence_window=RSI_divergence_window)\n",
    "\n",
    "# Part 2 \n",
    "\n",
    "# year_1 = 'Dec 2020'\n",
    "# year_2 = 'Mar 2021'\n",
    "\n",
    "# para = {\n",
    "# 'OPM':[False,12,'>'],\n",
    "# 'CFO':[True,0,'>'],\n",
    "# 'Net Cash Flow':[False,0,'>']\n",
    "#     }\n",
    "\n",
    "# para_s = {\n",
    "#     'Financing Margin %':[True,12,'>'],\n",
    "#     'Net_Profit':[True,0,'>'],\n",
    "#     'Net Cash Flow':[False,0,'>']\n",
    "# }\n",
    "\n",
    "\n",
    "def part_2(lst,b,year_1,year_2,para,para_s):\n",
    "    fs_final,cagr_final,ratios_final = screener_data_function(lst,b)\n",
    "    rename_columns(fs_final,cagr_final,ratios_final)\n",
    "\n",
    "    check_df = fs_final[(fs_final['Year']==year_1) | (fs_final['Year']==year_2)]\n",
    "    z = list(check_df['Company'].values)\n",
    "    check_df['Industry'] = bse_ticker['Industry'].loc[z].values\n",
    "\n",
    "    \n",
    "    # Remove Percentage \n",
    "    remove_percentage_function(check_df)\n",
    "#     display(check_df)    \n",
    "    # Convert Columns to Integers\n",
    "    column_type_convertor(check_df)\n",
    "    \n",
    "\n",
    "    \n",
    "    filtered_ticker = filter_stocks(para,para_s,check_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     filterd = check_df[(check_df['CFO']>CFO_amount)]\n",
    "#     display(filterd)\n",
    "#     filtered_ticker = list(filterd['Company'].values)\n",
    "    display(check_df)\n",
    "#     print(filtered_ticker)\n",
    "    return filtered_ticker\n",
    "\n",
    "# filtered_ticker = part_2(lst,b,year_1,year_2,para,para_s)\n",
    "# filtered_ticker\n",
    "\n",
    "# Part 4\n",
    "\n",
    "def part_4(filtered_ticker,closing_dataset):\n",
    "    if len(filtered_ticker)>1:\n",
    "        returns_dataset = returns_dataset_funtion(filtered_ticker,closing_dataset)\n",
    "        w = weightshrp(returns_dataset.dropna())\n",
    "#         display(w)\n",
    "    else:\n",
    "        print('Only 1 Company Found')\n",
    "        return pd.DataFrame()\n",
    "    return w\n",
    "\n",
    "# w = part_4(filtered_ticker,closing_dataset)\n",
    "# w\n",
    "\n",
    "# Part 5\n",
    "\n",
    "# future_start = '2021-04-30'\n",
    "# future_end= '2021-05-31'\n",
    "# future_index = pd.date_range(start=future_start,end=future_end)\n",
    "def part_5(dataset,future_start,future_end,w,filtered_ticker,m):\n",
    "#     display(w)\n",
    "    if w.shape[0] > 0:\n",
    "        future_index = pd.date_range(start=future_start,end=future_end)\n",
    "        future_price_dataset = dataset.loc[dataset.index.intersection(future_index)]\n",
    "        future_price = future_price_dataset.get(filtered_ticker)\n",
    "        po = np.asarray(future_price[:1])\n",
    "        p1 = np.asarray(future_price[-1:])\n",
    "#         m = 100000\n",
    "        port = m * np.array(w)\n",
    "        re = p1/po\n",
    "        print(np.sum(re * np.asarray(port).T))\n",
    "        return np.sum(re * np.asarray(port).T)\n",
    "    else:\n",
    "        print('Only 1 Company Found')\n",
    "        return m\n",
    "    \n",
    "    # main(cd,bse_ticker,start=start,end=end,year_1=year_1,year_2=year_2,future_start=future_start,future_end=future_end,m=100000)\n",
    "\n",
    "# part_5(cd,future_start,future_end,w)\n",
    "\n",
    "def main(start,end,future_start,future_end,money):\n",
    "    start = start\n",
    "    end = end\n",
    "\n",
    "    breakout_window=10\n",
    "    RSI_divergence_window = 30\n",
    "\n",
    "\n",
    "    lst,b,closing_dataset = part_1(cd,bse_ticker,start=start,end=end,breakout_window=breakout_window,RSI_divergence_window=RSI_divergence_window)\n",
    "\n",
    "    year_1 = 'Dec 2020'\n",
    "    year_2 = 'Mar 2021'\n",
    "\n",
    "    if len(lst) == 0:\n",
    "        print(\"RSI NOT FOUND\")\n",
    "    else:\n",
    "        filtered_ticker = part_2(lst,b,year_1,year_2,para,para_s)\n",
    "\n",
    "        w = part_4(filtered_ticker,closing_dataset)\n",
    "        display(w)\n",
    "\n",
    "        future_start = future_start\n",
    "        future_end= future_end\n",
    "        # future_index = pd.date_range(start=future_start,end=future_end)\n",
    "\n",
    "        money = part_5(cd,future_start,future_end,w,filtered_ticker,m)\n",
    "    return money\n",
    "\n",
    "# start = '2020-07-30'\n",
    "# end = '2021-07-30'\n",
    "# future_start = end\n",
    "# future_end= '2021-08-30'\n",
    "# main(start,end,future_start,future_end)\n",
    "\n",
    "start_list = pd.date_range(start='2020-04-01',end='2022-04-01',freq='M')\n",
    "m = 100000\n",
    "for i in range(0,len(start_list)):\n",
    "    try:\n",
    "        start = start_list[i]\n",
    "        end = start_list[i+12]\n",
    "        future_start = start_list[i+12]\n",
    "        future_end= start_list[i+13]\n",
    "        print('Start:',start)\n",
    "        print(\"End:\",end)\n",
    "        print(\"Future Start\",future_start)\n",
    "        print(\"Future End\",future_end)\n",
    "        m = main(start,end,future_start,future_end,m)\n",
    "        print(\"-------------------------------\")\n",
    "    except:\n",
    "        None\n",
    "\n",
    "start_list = pd.date_range(start='2020-04-01',end='2022-04-01',freq='M')\n",
    "m = 100000\n",
    "for i in range(0,len(start_list),2):\n",
    "    try:\n",
    "        start = start_list[i]\n",
    "        end = start_list[i+12]\n",
    "        future_start = start_list[i+12]\n",
    "        future_end= start_list[i+14]\n",
    "        print('Start:',start)\n",
    "        print(\"End:\",end)\n",
    "        print(\"Future Start\",future_start)\n",
    "        print(\"Future End\",future_end)\n",
    "        m = main(start,end,future_start,future_end,m)\n",
    "        print(\"-------------------------------\")\n",
    "    except:\n",
    "        None\n",
    "\n",
    "def main(start,end,future_start,future_end,money,year_1,year_2):\n",
    "    start = start\n",
    "    end = end\n",
    "\n",
    "    breakout_window=10\n",
    "    RSI_divergence_window = 30\n",
    "\n",
    "\n",
    "    lst,b,closing_dataset = part_1(cd,bse_ticker,start=start,end=end,breakout_window=breakout_window,RSI_divergence_window=RSI_divergence_window)\n",
    "\n",
    "\n",
    "\n",
    "    if len(lst) == 0:\n",
    "        print(\"RSI NOT FOUND\")\n",
    "    else:\n",
    "        filtered_ticker = part_2(lst,b,year_1,year_2,para,para_s)\n",
    "\n",
    "        w = part_4(filtered_ticker,closing_dataset)\n",
    "        display(w)\n",
    "\n",
    "        future_start = future_start\n",
    "        future_end= future_end\n",
    "        # future_index = pd.date_range(start=future_start,end=future_end)\n",
    "        money = part_5(cd,future_start,future_end,w,filtered_ticker,m)\n",
    "    return money\n",
    "\n",
    "start_list = pd.date_range(start='2020-04-01',end='2022-04-01',freq='M')\n",
    "m = 100000\n",
    "year_1 = 'Dec 2020'\n",
    "year_2 = 'Mar 2021'\n",
    "for i in range(0,len(start_list)):\n",
    "    start = start_list[i]\n",
    "    end = start_list[i+12]\n",
    "    future_start = start_list[i+12]\n",
    "    future_end= start_list[i+13]\n",
    "    print('Start:',start)\n",
    "    print(\"End:\",end)\n",
    "    print(\"Future Start\",future_start)\n",
    "    print(\"Future End\",future_end)\n",
    "    m = main(start,end,future_start,future_end,m,year_1,year_2)\n",
    "    print(\"-------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
